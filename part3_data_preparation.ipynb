{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f013a4de",
   "metadata": {},
   "source": [
    "# Part 3: Practical Data Preparation\n",
    "Handle categorical features using One-Hot Encoding and address class imbalance using SMOTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28793979",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66942ea1",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "Import necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96d28052",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd22950",
   "metadata": {},
   "source": [
    "## 2. Data Loading\n",
    "Load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ce5bed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    Load the synthetic health data from a CSV file.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the CSV file\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame containing the data\n",
    "    \"\"\"\n",
    "    # Load the CSV file using pandas\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b39269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>age</th>\n",
       "      <th>systolic_bp</th>\n",
       "      <th>diastolic_bp</th>\n",
       "      <th>glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoker_status</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>disease_outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-29 00:00:00.000000</td>\n",
       "      <td>57</td>\n",
       "      <td>113.063416</td>\n",
       "      <td>84.069561</td>\n",
       "      <td>117.475210</td>\n",
       "      <td>25.085796</td>\n",
       "      <td>no</td>\n",
       "      <td>62.719587</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-31 07:33:55.507789</td>\n",
       "      <td>57</td>\n",
       "      <td>121.598849</td>\n",
       "      <td>89.672279</td>\n",
       "      <td>85.120875</td>\n",
       "      <td>24.120608</td>\n",
       "      <td>no</td>\n",
       "      <td>76.314434</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-02-02 00:15:11.379377</td>\n",
       "      <td>57</td>\n",
       "      <td>126.623222</td>\n",
       "      <td>87.619685</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.819332</td>\n",
       "      <td>no</td>\n",
       "      <td>62.427785</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-02-04 09:37:12.589164</td>\n",
       "      <td>57</td>\n",
       "      <td>136.999366</td>\n",
       "      <td>89.199774</td>\n",
       "      <td>118.755648</td>\n",
       "      <td>25.039598</td>\n",
       "      <td>no</td>\n",
       "      <td>61.612981</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-02-04 20:56:52.838198</td>\n",
       "      <td>57</td>\n",
       "      <td>127.546919</td>\n",
       "      <td>92.644673</td>\n",
       "      <td>98.882007</td>\n",
       "      <td>24.895024</td>\n",
       "      <td>no</td>\n",
       "      <td>77.649615</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7321</th>\n",
       "      <td>150</td>\n",
       "      <td>2023-03-18 09:08:49.029823</td>\n",
       "      <td>54</td>\n",
       "      <td>115.038254</td>\n",
       "      <td>79.241741</td>\n",
       "      <td>84.586944</td>\n",
       "      <td>29.968156</td>\n",
       "      <td>no</td>\n",
       "      <td>73.599447</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7322</th>\n",
       "      <td>150</td>\n",
       "      <td>2023-03-20 14:38:22.129593</td>\n",
       "      <td>54</td>\n",
       "      <td>116.389186</td>\n",
       "      <td>70.464818</td>\n",
       "      <td>91.476621</td>\n",
       "      <td>29.519510</td>\n",
       "      <td>no</td>\n",
       "      <td>64.162701</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7323</th>\n",
       "      <td>150</td>\n",
       "      <td>2023-03-23 09:26:04.210673</td>\n",
       "      <td>54</td>\n",
       "      <td>123.419606</td>\n",
       "      <td>88.213054</td>\n",
       "      <td>96.985434</td>\n",
       "      <td>29.786678</td>\n",
       "      <td>no</td>\n",
       "      <td>71.641423</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7324</th>\n",
       "      <td>150</td>\n",
       "      <td>2023-03-27 14:17:19.255961</td>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.539940</td>\n",
       "      <td>85.670800</td>\n",
       "      <td>29.188655</td>\n",
       "      <td>no</td>\n",
       "      <td>72.781243</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7325</th>\n",
       "      <td>150</td>\n",
       "      <td>2023-04-12 04:12:38.529880</td>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.992331</td>\n",
       "      <td>94.694986</td>\n",
       "      <td>29.347033</td>\n",
       "      <td>no</td>\n",
       "      <td>66.888451</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7326 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      patient_id                   timestamp  age  systolic_bp  diastolic_bp  \\\n",
       "0              1  2023-01-29 00:00:00.000000   57   113.063416     84.069561   \n",
       "1              1  2023-01-31 07:33:55.507789   57   121.598849     89.672279   \n",
       "2              1  2023-02-02 00:15:11.379377   57   126.623222     87.619685   \n",
       "3              1  2023-02-04 09:37:12.589164   57   136.999366     89.199774   \n",
       "4              1  2023-02-04 20:56:52.838198   57   127.546919     92.644673   \n",
       "...          ...                         ...  ...          ...           ...   \n",
       "7321         150  2023-03-18 09:08:49.029823   54   115.038254     79.241741   \n",
       "7322         150  2023-03-20 14:38:22.129593   54   116.389186     70.464818   \n",
       "7323         150  2023-03-23 09:26:04.210673   54   123.419606     88.213054   \n",
       "7324         150  2023-03-27 14:17:19.255961   54          NaN     69.539940   \n",
       "7325         150  2023-04-12 04:12:38.529880   54          NaN     76.992331   \n",
       "\n",
       "      glucose_level        bmi smoker_status  heart_rate  disease_outcome  \n",
       "0        117.475210  25.085796            no   62.719587                0  \n",
       "1         85.120875  24.120608            no   76.314434                0  \n",
       "2               NaN  24.819332            no   62.427785                0  \n",
       "3        118.755648  25.039598            no   61.612981                0  \n",
       "4         98.882007  24.895024            no   77.649615                0  \n",
       "...             ...        ...           ...         ...              ...  \n",
       "7321      84.586944  29.968156            no   73.599447                0  \n",
       "7322      91.476621  29.519510            no   64.162701                0  \n",
       "7323      96.985434  29.786678            no   71.641423                0  \n",
       "7324      85.670800  29.188655            no   72.781243                0  \n",
       "7325      94.694986  29.347033            no   66.888451                0  \n",
       "\n",
       "[7326 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_df = load_data('data/synthetic_health_data.csv')\n",
    "#test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aae2f94",
   "metadata": {},
   "source": [
    "## 3. Categorical Feature Encoding\n",
    "Implement `encode_categorical_features` using `OneHotEncoder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a6f8046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical_features(df, column_to_encode='smoker_status'):\n",
    "    \"\"\"\n",
    "    Encode a categorical column using OneHotEncoder.\n",
    "    \n",
    "    Args:\n",
    "        df: Input DataFrame\n",
    "        column_to_encode: Name of the categorical column to encode\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with the categorical column replaced by one-hot encoded columns\n",
    "    \"\"\"\n",
    "    # 1. Extract the categorical column\n",
    "    categorical_col = df[[column_to_encode]]\n",
    "\n",
    "    # 2. Apply OneHotEncoder\n",
    "    encoder = OneHotEncoder(sparse_output = False, drop='first', handle_unknown='ignore')\n",
    "    encoded_array = encoder.fit_transform(categorical_col)\n",
    "\n",
    "    # 3. Create new column names\n",
    "    new_cols = encoder.get_feature_names_out([column_to_encode])\n",
    "    encoded_df = pd.DataFrame(encoded_array, columns=encoder.get_feature_names_out())\n",
    "\n",
    "    # 4. Replace the original categorical column with the encoded columns\n",
    "    df_encoded = df.drop(columns=[column_to_encode])\n",
    "    df_encoded = pd.concat([df_encoded, encoded_df], axis=1)\n",
    "    \n",
    "    return df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c349021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>age</th>\n",
       "      <th>systolic_bp</th>\n",
       "      <th>diastolic_bp</th>\n",
       "      <th>glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>disease_outcome</th>\n",
       "      <th>smoker_status_no</th>\n",
       "      <th>smoker_status_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-29 00:00:00.000000</td>\n",
       "      <td>57</td>\n",
       "      <td>113.063416</td>\n",
       "      <td>84.069561</td>\n",
       "      <td>117.475210</td>\n",
       "      <td>25.085796</td>\n",
       "      <td>62.719587</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-31 07:33:55.507789</td>\n",
       "      <td>57</td>\n",
       "      <td>121.598849</td>\n",
       "      <td>89.672279</td>\n",
       "      <td>85.120875</td>\n",
       "      <td>24.120608</td>\n",
       "      <td>76.314434</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-02-02 00:15:11.379377</td>\n",
       "      <td>57</td>\n",
       "      <td>126.623222</td>\n",
       "      <td>87.619685</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.819332</td>\n",
       "      <td>62.427785</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-02-04 09:37:12.589164</td>\n",
       "      <td>57</td>\n",
       "      <td>136.999366</td>\n",
       "      <td>89.199774</td>\n",
       "      <td>118.755648</td>\n",
       "      <td>25.039598</td>\n",
       "      <td>61.612981</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-02-04 20:56:52.838198</td>\n",
       "      <td>57</td>\n",
       "      <td>127.546919</td>\n",
       "      <td>92.644673</td>\n",
       "      <td>98.882007</td>\n",
       "      <td>24.895024</td>\n",
       "      <td>77.649615</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7321</th>\n",
       "      <td>150</td>\n",
       "      <td>2023-03-18 09:08:49.029823</td>\n",
       "      <td>54</td>\n",
       "      <td>115.038254</td>\n",
       "      <td>79.241741</td>\n",
       "      <td>84.586944</td>\n",
       "      <td>29.968156</td>\n",
       "      <td>73.599447</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7322</th>\n",
       "      <td>150</td>\n",
       "      <td>2023-03-20 14:38:22.129593</td>\n",
       "      <td>54</td>\n",
       "      <td>116.389186</td>\n",
       "      <td>70.464818</td>\n",
       "      <td>91.476621</td>\n",
       "      <td>29.519510</td>\n",
       "      <td>64.162701</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7323</th>\n",
       "      <td>150</td>\n",
       "      <td>2023-03-23 09:26:04.210673</td>\n",
       "      <td>54</td>\n",
       "      <td>123.419606</td>\n",
       "      <td>88.213054</td>\n",
       "      <td>96.985434</td>\n",
       "      <td>29.786678</td>\n",
       "      <td>71.641423</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7324</th>\n",
       "      <td>150</td>\n",
       "      <td>2023-03-27 14:17:19.255961</td>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.539940</td>\n",
       "      <td>85.670800</td>\n",
       "      <td>29.188655</td>\n",
       "      <td>72.781243</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7325</th>\n",
       "      <td>150</td>\n",
       "      <td>2023-04-12 04:12:38.529880</td>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.992331</td>\n",
       "      <td>94.694986</td>\n",
       "      <td>29.347033</td>\n",
       "      <td>66.888451</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7326 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      patient_id                   timestamp  age  systolic_bp  diastolic_bp  \\\n",
       "0              1  2023-01-29 00:00:00.000000   57   113.063416     84.069561   \n",
       "1              1  2023-01-31 07:33:55.507789   57   121.598849     89.672279   \n",
       "2              1  2023-02-02 00:15:11.379377   57   126.623222     87.619685   \n",
       "3              1  2023-02-04 09:37:12.589164   57   136.999366     89.199774   \n",
       "4              1  2023-02-04 20:56:52.838198   57   127.546919     92.644673   \n",
       "...          ...                         ...  ...          ...           ...   \n",
       "7321         150  2023-03-18 09:08:49.029823   54   115.038254     79.241741   \n",
       "7322         150  2023-03-20 14:38:22.129593   54   116.389186     70.464818   \n",
       "7323         150  2023-03-23 09:26:04.210673   54   123.419606     88.213054   \n",
       "7324         150  2023-03-27 14:17:19.255961   54          NaN     69.539940   \n",
       "7325         150  2023-04-12 04:12:38.529880   54          NaN     76.992331   \n",
       "\n",
       "      glucose_level        bmi  heart_rate  disease_outcome  smoker_status_no  \\\n",
       "0        117.475210  25.085796   62.719587                0               1.0   \n",
       "1         85.120875  24.120608   76.314434                0               1.0   \n",
       "2               NaN  24.819332   62.427785                0               1.0   \n",
       "3        118.755648  25.039598   61.612981                0               1.0   \n",
       "4         98.882007  24.895024   77.649615                0               1.0   \n",
       "...             ...        ...         ...              ...               ...   \n",
       "7321      84.586944  29.968156   73.599447                0               1.0   \n",
       "7322      91.476621  29.519510   64.162701                0               1.0   \n",
       "7323      96.985434  29.786678   71.641423                0               1.0   \n",
       "7324      85.670800  29.188655   72.781243                0               1.0   \n",
       "7325      94.694986  29.347033   66.888451                0               1.0   \n",
       "\n",
       "      smoker_status_yes  \n",
       "0                   0.0  \n",
       "1                   0.0  \n",
       "2                   0.0  \n",
       "3                   0.0  \n",
       "4                   0.0  \n",
       "...                 ...  \n",
       "7321                0.0  \n",
       "7322                0.0  \n",
       "7323                0.0  \n",
       "7324                0.0  \n",
       "7325                0.0  \n",
       "\n",
       "[7326 rows x 11 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_encode = encode_categorical_features(test_df)\n",
    "#test_encode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1563a4d2",
   "metadata": {},
   "source": [
    "## 4. Data Preparation\n",
    "Implement `prepare_data_part3` to handle the train/test split correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae3c9cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_part3(df, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Prepare data with categorical encoding.\n",
    "    \n",
    "    Args:\n",
    "        df: Input DataFrame\n",
    "        test_size: Proportion of data for testing\n",
    "        random_state: Random seed for reproducibility\n",
    "        \n",
    "    Returns:\n",
    "        X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    # 1. Encode categorical features using the encode_categorical_features function\n",
    "    df = encode_categorical_features(df)\n",
    "\n",
    "    # 2. Select relevant features (including the one-hot encoded ones) and the target\n",
    "    features = [col for col in df.columns if col not in ['disease_outcome', 'timestamp']]\n",
    "    X = df[features]\n",
    "    y = df['disease_outcome']\n",
    "\n",
    "    # 3. Handle missing values\n",
    "    imputer = SimpleImputer(strategy='mean') \n",
    "    imputed_df = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "    # 4. Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        imputed_df, y, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bc8a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_Xtrain, test_Xtest, test_ytrain, test_ytest = prepare_data_part3(test_df)\n",
    "#test_ytest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16be4de",
   "metadata": {},
   "source": [
    "## 5. Handling Imbalanced Data\n",
    "Implement `apply_smote` to oversample the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3024c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_smote(X_train, y_train, random_state=42):\n",
    "    \"\"\"\n",
    "    Apply SMOTE to oversample the minority class.\n",
    "    \n",
    "    Args:\n",
    "        X_train: Training features\n",
    "        y_train: Training target\n",
    "        random_state: Random seed for reproducibility\n",
    "        \n",
    "    Returns:\n",
    "        Resampled X_train and y_train with balanced classes\n",
    "    \"\"\"\n",
    "    # Apply SMOTE to balance the classes\n",
    "    smote = SMOTE(random_state=random_state)\n",
    "    X_resample, y_resample = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    return X_resample, y_resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8ed2bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "10577    1\n",
       "10578    1\n",
       "10579    1\n",
       "10580    1\n",
       "10581    1\n",
       "Name: disease_outcome, Length: 10582, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_Xresample, test_yresample = apply_smote(test_Xtrain, test_ytrain)\n",
    "#test_yresample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84178d69",
   "metadata": {},
   "source": [
    "## 6. Model Training and Evaluation\n",
    "Train a model on the SMOTE-resampled data and evaluate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b3b7a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logistic_regression(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Train a logistic regression model.\n",
    "    \n",
    "    Args:\n",
    "        X_train: Training features\n",
    "        y_train: Training target\n",
    "        \n",
    "    Returns:\n",
    "        Trained logistic regression model\n",
    "    \"\"\"\n",
    "    # Initialize and train a LogisticRegression model\n",
    "    model = LogisticRegression(max_iter=1000).fit(X_train, y_train)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def calculate_evaluation_metrics(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Calculate classification evaluation metrics.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model\n",
    "        X_test: Test features\n",
    "        y_test: Test target\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing accuracy, precision, recall, f1, auc, and confusion_matrix\n",
    "    \"\"\"\n",
    "    # 1. Generate predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # 2. Calculate metrics: accuracy, precision, recall, f1, auc\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "    # 3. Create confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # 4. Return metrics in a dictionary\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'auc': auc,\n",
    "        'confusion_matrix': conf_matrix\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dbf41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_model = train_logistic_regression(test_Xtrain, test_ytrain)\n",
    "#test_model\n",
    "\n",
    "#test_metrics = calculate_evaluation_metrics(test_model, test_Xtest, test_ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0f25bf",
   "metadata": {},
   "source": [
    "## 7. Save Results\n",
    "Save the evaluation metrics to a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "24fc8e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_eval_metrics(metrics):\n",
    "    \"\"\"\n",
    "    Save the evaluation metric to a text file.\n",
    "    \n",
    "    Args:\n",
    "        metrics: Evaluation metrics dictionary\n",
    "        xgb_auc: XGBoost AUC\n",
    "        \n",
    "    Returns:\n",
    "        Text file of evaluation metrics\n",
    "    \"\"\"\n",
    "    # 1. Create 'results' directory if it doesn't exist\n",
    "    os.makedirs('results', exist_ok=True)\n",
    "\n",
    "    # 2. Format metrics as strings\n",
    "    # 3. Write metrics to 'results/results_part3.txt'\n",
    "    filepath = 'results/results_part3.txt'\n",
    "    with open(filepath, 'w') as file:\n",
    "        for name, value in metrics.items():\n",
    "            file.write(f\"{name}: {value} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dd77de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_eval_metrics(test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89fe4cb",
   "metadata": {},
   "source": [
    "## 8. Compare Results\n",
    "Implement a function to compare model performance between balanced and imbalanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "23131f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(part1_metrics, part3_metrics):\n",
    "    \"\"\"\n",
    "    Calculate percentage improvement between models trained on imbalanced vs. balanced data.\n",
    "    \n",
    "    Args:\n",
    "        part1_metrics: Dictionary containing evaluation metrics from Part 1 (imbalanced)\n",
    "        part3_metrics: Dictionary containing evaluation metrics from Part 3 (balanced)\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with metric names as keys and improvement percentages as values\n",
    "    \"\"\"\n",
    "    # 1. Calculate percentage improvement for each metric\n",
    "    percentages = {}\n",
    "\n",
    "    # 2. Handle metrics where higher is better (most metrics) and where lower is better\n",
    "    for metric in ['accuracy', 'precision', 'recall', 'f1', 'auc']:\n",
    "        imbalanced = part1_metrics.get(metric, 0)\n",
    "        balanced = part3_metrics.get(metric, 0)\n",
    "        \n",
    "        if imbalanced > 0:\n",
    "            percentages[metric] = ((balanced - imbalanced) / imbalanced) * 100\n",
    "        else:\n",
    "            percentages[metric] = float('inf') if balanced > 0 else 0.0\n",
    "\n",
    "    # 3. Return a dictionary with metric names and improvement percentages\n",
    "    return percentages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee34a9a",
   "metadata": {},
   "source": [
    "## 9. Main Execution\n",
    "Run the complete workflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1f7489ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_metrics_from_txt(filename):\n",
    "    \"\"\"\n",
    "    Get metrics from text file (implemented this function instead because the main execution tries to open it as JSON)\n",
    "    \n",
    "    Args:\n",
    "        filename: File path\n",
    "        \n",
    "    Returns:\n",
    "        Parsed metrics\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()  \n",
    "            if ':' in line and line:  \n",
    "                key, value = line.split(':', 1)\n",
    "                key = key.strip()\n",
    "                value = value.strip()\n",
    "                \n",
    "                if value and value != '':\n",
    "                    try:\n",
    "                        metrics[key] = float(value)\n",
    "                    except ValueError:\n",
    "                        print(f\"Skipping non-numeric value for '{key}': '{value}'\")\n",
    "                        continue\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a25441cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8547\n",
      "precision: 0.3885\n",
      "recall: 0.8531\n",
      "f1_score: 0.5339\n",
      "auc: 0.8540\n",
      "\n",
      "Model Comparison (improvement percentages):\n",
      "accuracy: -6.77%\n",
      "precision: -41.26%\n",
      "recall: 183.72%\n",
      "f1: -100.00%\n",
      "auc: -5.99%\n"
     ]
    }
   ],
   "source": [
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Load data\n",
    "    data_file = 'data/synthetic_health_data.csv'\n",
    "    df = load_data(data_file)\n",
    "    \n",
    "    # 2. Prepare data with categorical encoding\n",
    "    X_train, X_test, y_train, y_test = prepare_data_part3(df)\n",
    "    \n",
    "    # 3. Apply SMOTE to balance the training data\n",
    "    X_train_resampled, y_train_resampled = apply_smote(X_train, y_train)\n",
    "    \n",
    "    # 4. Train model on resampled data\n",
    "    model = train_logistic_regression(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # 5. Evaluate on original test set\n",
    "    metrics = calculate_evaluation_metrics(model, X_test, y_test)\n",
    "    \n",
    "    # 6. Print metrics\n",
    "    for metric, value in metrics.items():\n",
    "        if metric != 'confusion_matrix':\n",
    "            print(f\"{metric}: {value:.4f}\")\n",
    "    \n",
    "    # 7. Save results\n",
    "    save_eval_metrics(metrics)\n",
    "    \n",
    "    # 8. Load Part 1 results for comparison\n",
    "    try:\n",
    "        part1_metrics = parse_metrics_from_txt('results/results_part1.txt')\n",
    "        \n",
    "        # 9. Compare models\n",
    "        comparison = compare_models(part1_metrics, metrics)\n",
    "        print(\"\\nModel Comparison (improvement percentages):\")\n",
    "        for metric, improvement in comparison.items():\n",
    "            print(f\"{metric}: {improvement:.2f}%\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Part 1 results not found. Run part1_introduction.ipynb first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ceb7924",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
